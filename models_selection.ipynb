{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e98c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324eb327",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Splitting to Train, Test, Validation and Loading data - was run once and test and validation files were used for all files\n",
    "data1 = pd.read_csv(\"data.csv\")\n",
    "train_data, temp_data = train_test_split(data1, test_size=0.3, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=2/3, random_state=42)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "validation_data = pd.read_csv(\"validation_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af40806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing\n",
      "Converting Julian Time\n",
      "Adding 4th of July feature\n",
      "Adding season feature\n",
      "Handling nulls\n",
      "Converting dates to hours\n",
      "Adding hours to containment feature\n",
      "Adding is_day feature\n",
      "Adding days_till_cont feature\n",
      "Create bins for discovered hour\n",
      "Add holiday feature\n",
      "KNN classification starting...\n",
      "Creating dummies for data\n",
      "FIRE_SIZE_CLASS\n",
      "Season\n",
      "discovery_month\n",
      "classified_as\n",
      "Creating dummies for test_data\n",
      "FIRE_SIZE_CLASS\n",
      "Season\n",
      "discovery_month\n",
      "classified_as\n",
      "Creating dummies for validation_data\n",
      "FIRE_SIZE_CLASS\n",
      "Season\n",
      "discovery_month\n",
      "classified_as\n",
      "Removing features for model\n"
     ]
    }
   ],
   "source": [
    "data,test_data,validation_data = preprocess_data(data,test_data,validation_data,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2abfb",
   "metadata": {},
   "source": [
    "#  X & Y Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddeac6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STAT_CAUSE_DESCR', 'LATITUDE', 'LONGITUDE',\n",
       "       'is_week_before_or_after_july_4', 'HOURS_TO_CONTAIN', 'IS_DAY',\n",
       "       'DISCOVERY_HOUR_BIN_10-16', 'DISCOVERY_HOUR_BIN_16-22',\n",
       "       'DISCOVERY_HOUR_BIN_22-4', 'DISCOVERY_HOUR_BIN_4-10', 'is_weekend',\n",
       "       'is_holiday', 'FIRE_SIZE_CLASS_A', 'FIRE_SIZE_CLASS_B',\n",
       "       'FIRE_SIZE_CLASS_C', 'FIRE_SIZE_CLASS_D', 'FIRE_SIZE_CLASS_E',\n",
       "       'FIRE_SIZE_CLASS_F', 'FIRE_SIZE_CLASS_G', 'Season_Fall',\n",
       "       'Season_Spring', 'Season_Summer', 'Season_Winter', 'discovery_month_1',\n",
       "       'discovery_month_2', 'discovery_month_3', 'discovery_month_4',\n",
       "       'discovery_month_5', 'discovery_month_6', 'discovery_month_7',\n",
       "       'discovery_month_8', 'discovery_month_9', 'discovery_month_10',\n",
       "       'discovery_month_11', 'discovery_month_12', 'classified_as_Arson',\n",
       "       'classified_as_Campfire', 'classified_as_Children',\n",
       "       'classified_as_Debris Burning', 'classified_as_Equipment Use',\n",
       "       'classified_as_Fireworks', 'classified_as_Lightning',\n",
       "       'classified_as_Miscellaneous', 'classified_as_Powerline',\n",
       "       'classified_as_Railroad', 'classified_as_Smoking',\n",
       "       'classified_as_Structure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa69f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns = ['STAT_CAUSE_DESCR'])\n",
    "y_train = data['STAT_CAUSE_DESCR']\n",
    "X_test = test_data.drop(columns = ['STAT_CAUSE_DESCR'])\n",
    "y_test = test_data['STAT_CAUSE_DESCR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f7f99",
   "metadata": {},
   "source": [
    "# Encoding y to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894b4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_y_train = le.fit_transform(y_train)\n",
    "encoded_y_test = le.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79561e",
   "metadata": {},
   "source": [
    "# Random Forest, Grid Search CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4afb1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.7853024205728061\n",
      "best params:\n",
      "{'min_samples_leaf': 16, 'min_samples_split': 120, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "params_grid = { \n",
    "    'n_estimators': [30,40],\n",
    "    'min_samples_leaf': [16,25,50],\n",
    "    'min_samples_split': [250,80,120]\n",
    "}\n",
    "\n",
    "\n",
    "# Define the scorer as ROC AUC score\n",
    "scorer = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr')\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=params_grid, cv=5,scoring=scorer)\n",
    "grid.fit(X_train, encoded_y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predict probabilities on the filtered test data\n",
    "predictions_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc_roc = roc_auc_score(encoded_y_test, predictions_proba,multi_class='ovr')\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "print(\"best params:\")\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b4442",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbf530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6516877736682029\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regression classifier\n",
    "logistic_model = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "# Train the model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = logistic_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC score\n",
    "auc_roc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(str(auc_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb63da5",
   "metadata": {},
   "source": [
    "# Naive bayessian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd0577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.6996371824041304\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = nb_classifier.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC score\n",
    "auc_roc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d43d6",
   "metadata": {},
   "source": [
    "# Neural Network -  was not successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70060048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Convert DataFrame to NumPy arrays\n",
    "# X_train_np = X_train.values\n",
    "# X_test_np = X_test.values\n",
    "\n",
    "# # Encode categorical labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "# X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "# # Define neural network architecture\n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return torch.log_softmax(x, dim=1)\n",
    "\n",
    "# # Instantiate the model\n",
    "# input_size = X_train_np.shape[1]  # Number of features\n",
    "# hidden_size = 64\n",
    "# output_size = 12  \n",
    "# model = Classifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# def roc_auc_loss(y_true, y_pred):\n",
    "#     try:\n",
    "#         auc = roc_auc_score(y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy(), average='macro', multi_class='ovo')\n",
    "#         return torch.tensor(1 - auc, dtype=torch.float32, requires_grad=True)  # Return 1 - ROC AUC as the loss\n",
    "#     except ValueError:\n",
    "#         return torch.tensor(0.5, dtype=torch.float32, requires_grad=True)  # Return 0.5 if AUC cannot be computed\n",
    "\n",
    "# # Define optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = roc_auc_loss(y_train_tensor, torch.exp(outputs))  # Use torch.exp(outputs) to convert log probabilities to probabilities\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(X_test_tensor)\n",
    "#     _, predicted = torch.max(outputs, 1)\n",
    "#     # Use predicted probabilities instead of predicted classes for ROC AUC calculation\n",
    "#     roc_auc = roc_auc_score(y_test_encoded, torch.exp(outputs).cpu().numpy(), average='macro', multi_class='ovr')\n",
    "\n",
    "# print(f'Test ROC AUC: {roc_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9a0af",
   "metadata": {},
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628cbe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=  45.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.1;, score=nan total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=40, subsample=0.3;, score=nan total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.1;, score=nan total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=30, subsample=0.3;, score=nan total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.1;, score=nan total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=40, subsample=0.3;, score=nan total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.1;, score=nan total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 350, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 633, in roc_auc_score\n",
      "    raise ValueError(\"multi_class must be in ('ovo', 'ovr')\")\n",
      "ValueError: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Avraham\\.conda\\envs\\competitive\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=30, subsample=0.3;, score=nan total time=   5.6s\n",
      "AUC-ROC Score: 0.7558887903211916\n",
      "best parameters:\n",
      "{'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 40, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost classifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Define the parameters grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [40, 30],\n",
    "    'max_depth': [5,10],\n",
    "    'learning_rate': [0.1,0.3],\n",
    "    'subsample': [0.1,0.3],\n",
    "    'colsample_bytree': [0.1,0.3]\n",
    "}\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=3)\n",
    "grid_search.fit(X_train, encoded_y_train)\n",
    "\n",
    "# # Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# # Train the model with the best parameters\n",
    "best_xgb_model = XGBClassifier(**best_params)\n",
    "best_xgb_model.fit(X_train, encoded_y_train)\n",
    "\n",
    "# # Make predictions\n",
    "y_pred_proba = best_xgb_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC score using one-vs-rest (ovr) strategy\n",
    "auc_roc_score = roc_auc_score(encoded_y_test, y_pred_proba, multi_class='ovr')\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)\n",
    "print(\"best parameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9da8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.7558887903211916\n",
      "best parameters:\n",
      "{'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 40, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC-ROC Score:\", auc_roc_score)\n",
    "print(\"best parameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
